{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9275cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "os.chdir(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from load_emails import main as load_all\n",
    "\n",
    "import load_emails\n",
    "\n",
    "df = pd.DataFrame(load_emails.load_folder(load_emails.SPAM_DIR, \"spam\") + load_emails.load_folder(load_emails.HAM_DIR, \"ham\"))\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10feb4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"body_length\"] = df[\"body\"].str.len()\n",
    "df[\"body_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cfd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SPAM SAMPLE ===\")\n",
    "print(df[df[\"label\"] == \"spam\"].sample(1, random_state=1)[\"body\"].values[0])\n",
    "\n",
    "print(\"\\n=== HAM SAMPLE ===\")\n",
    "print(df[df[\"label\"] == \"ham\"].sample(1, random_state=1)[\"body\"].values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"[A-Za-z']+\", text.lower())\n",
    "\n",
    "spam_words = Counter()\n",
    "ham_words = Counter()\n",
    "\n",
    "for txt in df[df[\"label\"]==\"spam\"][\"body\"].dropna():\n",
    "    spam_words.update(tokenize(txt))\n",
    "\n",
    "for txt in df[df[\"label\"]==\"ham\"][\"body\"].dropna():\n",
    "    ham_words.update(tokenize(txt))\n",
    "\n",
    "print(\"Top spam words:\", spam_words.most_common(20))\n",
    "print(\"\\nTop ham words:\", ham_words.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"body\"].str.len() == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"subject\"].fillna(\"\") + \" \" + df[\"body\"].fillna(\"\")\n",
    "df[\"text\"].str.len().describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=None,    # keep stopwords for now, TF-IDF will handle it\n",
    "    ngram_range=(1, 2), # unigrams + bigrams (very important for spam)\n",
    "    max_features=5000   # keeps vector size manageable\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df[\"text\"])\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# target labels\n",
    "y = df[\"label\"]\n",
    "\n",
    "# split (stratify to preserve spam/ham ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# train model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef27242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_lr, labels=[\"ham\", \"spam\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"ham\", \"spam\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
